---
title: "Seventh Blog Post"
subtitle: "Logisitic and Decision Tree Models"
author: "TEAM NA"
date: "2024-04-29"
draft: false
---


```{r include=F}
library(tidyverse)
library(lubridate)
library(patchwork)
library(pheatmap)
library(gridExtra)
library(data.table)
library(ggplot2)
library(viridis)
library(dplyr)
library(sp)
library(sf)
library(MLmetrics)
library(MASS)
library(rpart)
library(rpart.plot)
library(pROC)
library(gt)
data <- read_rds("dataset/load_and_clean_data.rds")
data$ARREST_DATE <- as.Date(data$ARREST_DATE, "%m/%d/%Y")
```

```{r echo=FALSE}
get_season <- function(date) {
  month <- month(date)
  year <- year(date)
  if (month %in% c(12, 1, 2)) {
    season <- "Winter"
  } else if (month %in% c(3, 4, 5)) {
    season <- "Spring"
  } else if (month %in% c(6, 7, 8)) {
    season <- "Summer"
  } else {
    season <- "Autumn"
  }
  paste(season, year)
}
```

```{r echo=F}
#cumulative counts 
data$Season <- sapply(data$ARREST_DATE, get_season)
data_filtered <- filter(data, year(ARREST_DATE) %in% c(2022, 2023))

season_counts <- data_filtered %>%
  group_by(Season) %>%
  summarise(Count = n()) %>%
  mutate(Year = substr(Season, 8, 11)) %>%
  mutate(Season = factor(substr(Season, 1, 6), levels = c("Spring", "Summer", "Autumn","Winter"))) %>%
  arrange(Season)

plot_count<-ggplot(season_counts, aes(x = Season, y = Count, fill = Year)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7)) +
  scale_fill_manual(values = c("2022" = "steelblue", "2023" = "lightgreen")) +
  theme_minimal() +
  labs(title = "Total Crime Counts per Season", 
       x = "Season", 
       y = "Number of Incidents",
       fill = "Year") 

```

```{r echo=FALSE}
#felcony
data$Season <- sapply(data$ARREST_DATE, get_season)
felony_assault_data <- filter(data, OFNS_DESC == "FELONY ASSAULT", year(ARREST_DATE) %in% c(2022, 2023))

season_felony_count <- felony_assault_data %>%
  group_by(Season) %>%
  summarise(Count = n())%>%
  mutate(Year = substr(Season, 8, 11)) %>%
  mutate(Season = factor(substr(Season, 1, 6), levels = c("Spring", "Summer", "Autumn","Winter"))) %>%
  arrange(Season)
  
plotfa<- ggplot(season_felony_count, aes(x = Season, y = Count, fill = Year)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7)) +
  scale_fill_manual(values = c("2022" = "steelblue", "2023" = "lightgreen")) +
  theme_minimal() +
  labs(title = "Felony Assault", 
       x = "Season", 
       y = "Number of Incidents",
       fill = "Year")

```

```{r echo=F}
#petit larceny
data$Season <- sapply(data$ARREST_DATE, get_season)
petit_larceny_data <- filter(data, OFNS_DESC == "PETIT LARCENY", year(ARREST_DATE) %in% c(2022, 2023))

petit_larceny_counts <- petit_larceny_data %>%
  group_by(Season) %>%
  summarise(Count = n()) %>%
  mutate(Year = substr(Season, 8, 11)) %>%
  mutate(Season = factor(substr(Season, 1, 6), levels = c("Spring", "Summer", "Autumn", "Winter"))) %>%
  arrange(Season)

plotpl<- ggplot(petit_larceny_counts, aes(x = Season, y = Count, fill = Year)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7)) +
  scale_fill_manual(values = c("2022" = "steelblue", "2023" = "lightgreen")) +
  theme_minimal() +
  labs(title = "Petit Larceny", 
       x = "Season", 
       y = "Number of Incidents",
       fill = "Year")
```

```{r echo=F}
# assault 3
data$Season <- sapply(data$ARREST_DATE, get_season)
assault_3_data <- filter(data, OFNS_DESC == "ASSAULT 3 & RELATED OFFENSES", year(ARREST_DATE) %in% c(2022, 2023))

assault_3_counts <- assault_3_data %>%
  group_by(Season) %>%
  summarise(Count = n()) %>%
  mutate(Year = substr(Season, 8, 11)) %>%
  mutate(Season = factor(substr(Season, 1, 6), levels = c("Spring", "Summer", "Autumn", "Winter"))) %>%
  arrange(Season)

 plota3<- ggplot(assault_3_counts, aes(x = Season, y = Count, fill = Year)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7)) +
  scale_fill_manual(values = c("2022" = "steelblue", "2023" = "lightgreen")) +
  theme_minimal() +
  labs(title = "Assault 3 ", 
       x = "Season", 
       y = "Number of Incidents",
       fill = "Year")

```
```{r echo=FALSE}
combine_plot_crime<-plot_count+plota3+plotfa+plotpl+
   plot_layout(nrow = 2, ncol = 2)
combine_plot_crime
```


### Logistic Regression Model 

```{r echo=FALSE, message=FALSE, warning= FALSE}
ds <- read_rds("dataset/load_and_clean_data.rds") 

ds$y <- ifelse(ds$OFNS_DESC == "ASSAULT 3 & RELATED OFFENSES",1,0)
ds$PD_DESC <- NULL
ds$OFNS_DESC  <- NULL
ds$`New Georeferenced Column` <- NULL
ds$ARREST_PRECINCT <- as.factor(ds$ARREST_PRECINCT)

set.seed(123)
size <- round(dim(ds)[1]*0.8)
index <- sample(1:dim(ds)[1],size ,replace = F)
data_train <- ds[index,]
data_valid <- ds[-index,]

```

To identify patterns in ASSAULT 3 by considering various factors such as age, gender, race of the perpetrator, as well as environmental factors like temperature and weather conditions, we decide to build a logistic regression model to predict the likelihood of an arrest being for "ASSAULT 3 & RELATED OFFENSES". This helps police understand under what circumstances such crimes are more likely to occur, aiding in the development of proactive policing strategies.

first,we use a binary response variable y is created to represent whether each arrest falls into this category. The data is then split into training and validation sets, we randomly select 80% to be training set, 20% to be validation set.

### Logisitic Model result
```{r echo=FALSE, message=FALSE, warning= FALSE}
model_lr <- glm(y ~ .
                , family = binomial
                , data = data_train)
```

```{r echo=FALSE, message=FALSE, warning= FALSE}
summary(model_lr)
```


# Confusion Matrix for log model
```{r  echo=FALSE, message=FALSE, warning= FALSE}
library(MLmetrics)
predict_lr <- predict(model_lr,data_valid,type = "response")
predict_classes <- ifelse(predict_lr > 0.5, 1, 0)
```

```{r  echo=FALSE, message=FALSE, warning= FALSE}

conf_matrix <- table(Predicted = predict_classes, Actual = data_valid$y)

print(conf_matrix)

accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
print(paste("Accuracy:", accuracy))
print(paste("AUC:", AUC(predict_lr,data_valid$y)))
```

To better evaluate the model, We build a confusion matrix to show the accuracy of the model, which is the proportion of correct predictions (true positives and true negatives) out of the total predictions, is calculated at approximately 84.88%. This indicates that the model performs well in general. Additionally, the Area Under the Curve (AUC) score of 0.8222, shown below the confusion matrix, further confirms the model's effectiveness in distinguishing between the two classes. 

```{r  echo=FALSE, message=FALSE, warning= FALSE}
data_valid[which(predict_lr>0.70), ]
```

We filtered out cases where the logistic regression model predicted a probability greater than 0.70 for the outcome of interest, focusing on instances where the model confidently predicted an arrest as "ASSAULT 3."

The results indicate that "ASSAULT 3" crimes typically occur between March and December, especially during rainy or cloudy weather with temperatures above zero Celsius. These incidents predominantly happen in central Brooklyn, the Bronx, and uptown Manhattan. At the precinct level, Precincts 67, 32, and 42 are notable hotspots.

Demographically, the majority of offenders are African American or White Hispanic, often around or below 18 years of age. Interestingly, the data also shows a significant proportion of female offenders, primarily involved in misdemeanor-level offenses.



## Decision Trees model
```{r  echo=FALSE, message=FALSE, warning= FALSE}

train_dummy <- model.matrix(~ LAW_CAT_CD
                            +ARREST_BORO+ARREST_PRECINCT
                            +AGE_GROUP + PERP_SEX
                            +PERP_RACE +conditions            
                            - 1
                            , data = data_train)
train_all <- data.frame(train_dummy
                        , ARREST_DATE  = data_train$ARREST_DATE
                        , temp = data_train$temp
                        , windspeed = data_train$windspeed
                        , cloudcover = data_train$cloudcover
                       ,y = data_train$y
                        )
```


```{r  echo=FALSE, message=FALSE, warning= FALSE}

valid_dummy <- model.matrix(~ LAW_CAT_CD
                            +ARREST_BORO+ARREST_PRECINCT
                            +AGE_GROUP + PERP_SEX
                            +PERP_RACE +conditions            
                            - 1
                            , data = data_valid)
valid_all <- data.frame(valid_dummy
                        , ARREST_DATE  = data_valid$ARREST_DATE
                        , temp = data_valid$temp
                        , windspeed = data_valid$windspeed
                        , cloudcover = data_valid$cloudcover
                        ,y = data_valid$y
                        )



```

Nextï¼Œ we decide to use Decision tree model to predict whether an arrest falls into the category of "ASSAULT 3" based on various demographic, legal, and environmental factors.It will provides a clear framework for understanding and predicting "ASSAULT 3", helping law enforcement and policymakers make informed decisions based on data-driven insights. 


```{r  echo=FALSE, message=FALSE, warning= FALSE}
model_tree <- rpart(y ~ .
                    , data = train_all, method = "class"
                    ,control=rpart.control(minsplit=1, minbucket=1, cp=0.0003))
rpart.plot(model_tree,cex=0.35,type = 3) ###cex=0.35,type = 3
```
The decision tree model classifies incidents of "ASSAULT 3" based on a probability threshold of 50%. For instance, if the individual is a male, identified as white, and located in Precinct 14, there is only a 22%(Last row, fifth from the begin) chance of an assault crime occurring, thus placing it in the category of unlikely to experience "ASSAULT 3."

Conversely, the model predicts a higher likelihood that 76% probability((Last row, fourth from the end)) of an "ASSAULT 3" related crime if the perpetrator is a female, non-white, located in Precinct 42, and the cloud cover exceeds 55%. 

This scenario highlights how the decision tree uses combinations of demographic and environmental factors to determine the probability of assault-related offenses.

```{r echo=FALSE, message=FALSE, warning= FALSE}
summary(model_tree)
```


#Confusion Matrix 
```{r  echo=FALSE, message=FALSE, warning= FALSE}
predict_tree <- predict(model_tree,valid_all,type = "prob")[,2]
predict_classes_tree <- ifelse(predict_tree > 0.5, 1, 0)
```



```{r  echo=FALSE, message=FALSE, warning= FALSE}

conf_matrix_tree <- table(Predicted = predict_classes_tree, Actual = data_valid$y)


print(conf_matrix_tree)

accuracy_tree <- sum(diag(conf_matrix_tree)) / sum(conf_matrix_tree)
print(paste("Accuracy:", accuracy_tree))
print(paste("AUC:", AUC(predict_tree,data_valid$y)))
```

To better evaluate the model, We build a confusion matrix to show the accuracy of the model, which is the proportion of correct predictions (true positives and true negatives) out of the total predictions, is calculated at approximately 84.86%. This indicates that the model performs well in general. Additionally, the Area Under the Curve (AUC) score of 0.7897, shown below the confusion matrix, further confirms the model's effectiveness in distinguishing between the two classes. 



## Compare the Accuracy between these two models
```{r  include=FALSE}
library(pROC)
roc_lr <- roc(data_valid$y,predict_lr)
roc_tree <- roc(data_valid$y,predict_tree)

```


```{r  echo=FALSE, message=FALSE, warning= FALSE}
roc_df <- data.frame(
  Sensitivity = c(0, roc_lr$sensitivities),
  OneMinusSpecificity = c(0, 1 - roc_lr$specificities),
  Model = rep("Logistic", length(roc_lr$sensitivities) + 1)
)

roc_df <- rbind(roc_df,
                data.frame(
                  Sensitivity = c(0, roc_tree$sensitivities),
                  OneMinusSpecificity = c(0, 1 - roc_tree$specificities),
                  Model = rep("Tree", length(roc_tree$sensitivities) + 1)
                ))

library(ggplot2)

auc_plot <- ggplot(roc_df, aes(x = OneMinusSpecificity, y = Sensitivity, color = Model)) +
  geom_line() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(title = "AUC Comparison", x = "1 - Specificity", y = "Sensitivity") +
  theme_minimal()
auc_plot
```

We use the ROC curves to evaluate the performance of classification models. The area under the curve (AUC) for each model can be used to quantify the overall performance. The higher the AUC, the better the model's ability to discriminate between the two classes.The logistic model (red curve) appears to outperform the tree model (blue curve) by achieving a higher AUC, which indicates that it has a better overall classification performance for the arrest data. 



### Polish our graphs and charts

Titles and Labels: We are going to craft clear, descriptive titles and axis labels that succinctly convey the meaning of the data, and use numbers to label each in sequence.

Legends: We need to ensure legends are clear and correctly positioned. Modify legend titles to be informative and concise. Use a color scale that is intuitive and provides good contrast for the data represented.

Captions: we need to include captions that explain the visualization in a bit more detail, highlighting key findings or noting any caveats about the data.

Scales and Breaks: We decide to adjust scales and breaks on axes to make sure they are appropriate for the dataâ€™s range and distribution. 

Color Choices: We will ensure consistency across multiple visualizations, with the same color schemes, label formats, and styles used throughout.


We are planning to add a interactive graph that could brief will the crime variables in our dataset.



